# -*- coding: utf-8 -*-
"""pyspark_rdd_actions_transformations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbiRTubXJ5PK3xuhp66MqMbOc32TOihu
"""

!apt-get install openjdk-8-jdk -y

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

!pip install findspark

!pip install pyspark

import findspark
findspark.init()

from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").appName("Colab PySpark").getOrCreate()

from pyspark import SparkContext

sc = spark.sparkContext

my_rdd = sc.parallelize([20,40,50,60,70])

type(my_rdd)

my_rdd.collect()

!wget https://raw.githubusercontent.com/futurexskill/bidata/master/retailstore.csv

!ls

my_csv_rdd = sc.textFile('retailstore.csv')

my_csv_rdd.collect()

type(my_csv_rdd)

my_csv_rdd.first()

my_csv_rdd.take(3)

for line in my_csv_rdd.collect():
  print(line)
  print("hello")

my_csv_rdd_2 = my_csv_rdd.map(lambda x : x.replace("Male","M"))

my_csv_rdd_2.collect()

femaleCustomers=my_csv_rdd_2.filter(lambda x: "Female" in x)

femaleCustomers.collect()

femaleCustomers.count()

words = femaleCustomers.flatMap(lambda line: line.split(","))

words.collect()

words.count()

rdd1 = sc.parallelize(["a","b","c","d","e"])

rdd2 = sc.parallelize(["c","e","k","l"])

rdd1.union(rdd2).collect()

rdd1.union(rdd2).distinct().collect()

rdd1.intersection(rdd2).collect()

my_csv_rdd.collect()

def transformRDD(customer) :
    words =customer.split(",")
    #convert male to 0 and female to 1
    if words[2] == "Male" :
         words[2]="0"
    else :
         words[2]="1"
    #Convert N to 0 and Y to 1 for the purchased value
    if words[4] == "N" :
         words[4]="0"
    else :
         words[4]="1"
    #Convert Country to upper case
    words[3] = words[3].upper()
    return ",".join(words)

my_csv_transformed = my_csv_rdd.map(transformRDD)

my_csv_transformed.collect()

sampleRDD = sc.parallelize([10, 20, 30,40])

sampleRDD.reduce(lambda a, b: a + b)

